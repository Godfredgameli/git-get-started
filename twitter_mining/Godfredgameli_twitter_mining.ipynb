{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6f5Nk1gXRJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "2bbcc7c3-4735-4540-c004-9853409ccbeb"
      },
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"name\": \"godfred_gameli.ipynb\",\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"1YRNpdG68VGM\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 158\n",
        "        },\n",
        "        \"outputId\": \"30f8e3e9-e29c-4cfc-d726-798467375494\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"!pip install tweet-preprocessor\\n\",\n",
        "        \"!pip install textblob\\n\",\n",
        "        \"!pip install tweet-preprocessor\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"Collecting tweet-preprocessor\\n\",\n",
        "            \"  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\\n\",\n",
        "            \"Installing collected packages: tweet-preprocessor\\n\",\n",
        "            \"Successfully installed tweet-preprocessor-0.6.0\\n\",\n",
        "            \"Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\\n\",\n",
        "            \"Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\\n\",\n",
        "            \"Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\\n\",\n",
        "            \"Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"B0Uh5g2Y8Uhf\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"import sys\\n\",\n",
        "        \"import os\\n\",\n",
        "        \"import json\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"import matplotlib.pyplot as plt\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"syT4ggI88a7i\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 87\n",
        "        },\n",
        "        \"outputId\": \"2d6dfacc-9a48-415c-9e4b-06d956f58bd7\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"#Import the necessary methods from tweepy library  \\n\",\n",
        "        \"\\n\",\n",
        "        \"#install tweepy if you don't have it\\n\",\n",
        "        \"#!pip install tweepy\\n\",\n",
        "        \"import tweepy\\n\",\n",
        "        \"from tweepy.streaming import StreamListener\\n\",\n",
        "        \"from tweepy import OAuthHandler\\n\",\n",
        "        \"from tweepy import Stream\\n\",\n",
        "        \"\\n\",\n",
        "        \"#sentiment analysis package\\n\",\n",
        "        \"#!pip install textblob\\n\",\n",
        "        \"from textblob import TextBlob\\n\",\n",
        "        \"\\n\",\n",
        "        \"#general text pre-processor\\n\",\n",
        "        \"#!pip install nltk\\n\",\n",
        "        \"import nltk\\n\",\n",
        "        \"from nltk.corpus import stopwords\\n\",\n",
        "        \"nltk.download('stopwords')\\n\",\n",
        "        \"nltk.download('punkt')\\n\",\n",
        "        \"from nltk.tokenize import word_tokenize\\n\",\n",
        "        \"\\n\",\n",
        "        \"#tweet pre-processor \\n\",\n",
        "        \"#!pip install tweet-preprocessor\\n\",\n",
        "        \"import preprocessor as ppr\\n\",\n",
        "        \"\\n\",\n",
        "        \"import twitter_credentials\\n\",\n",
        "        \"import re\\n\",\n",
        "        \"import string\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"text\": [\n",
        "            \"[nltk_data] Downloading package stopwords to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Unzipping corpora/stopwords.zip.\\n\",\n",
        "            \"[nltk_data] Downloading package punkt to /root/nltk_data...\\n\",\n",
        "            \"[nltk_data]   Unzipping tokenizers/punkt.zip.\\n\"\n",
        "          ],\n",
        "          \"name\": \"stdout\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"5XxyUHTv7l1_\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"class tweetsearch():\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    This is a basic class to search and download twitter data.\\n\",\n",
        "        \"    You can build up on it to extend the functionalities for more \\n\",\n",
        "        \"    sophisticated analysis\\n\",\n",
        "        \"    '''\\n\",\n",
        "        \"    def __init__(self,cols=None,auth=None):\\n\",\n",
        "        \"        #\\n\",\n",
        "        \"        if not cols is None:\\n\",\n",
        "        \"            self.cols = cols\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            self.cols = ['id', 'created_at', 'source', 'original_text','clean_text', \\n\",\n",
        "        \"                    'sentiment','polarity','subjectivity', 'lang',\\n\",\n",
        "        \"                    'favorite_count', 'retweet_count', 'original_author',   \\n\",\n",
        "        \"                    'possibly_sensitive', 'hashtags',\\n\",\n",
        "        \"                    'user_mentions', 'place', 'place_coord_boundaries']\\n\",\n",
        "        \"            \\n\",\n",
        "        \"        if auth is None:\\n\",\n",
        "        \"            #Variables that contains the user credentials to access Twitter API \\n\",\n",
        "        \"            #consumer_key = os.environ.get('TWITTER_API_KEY')\\n\",\n",
        "        \"            #consumer_secret = os.environ.get('TWITTER_API_SECRET')\\n\",\n",
        "        \"            #access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\\n\",\n",
        "        \"            #access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"            #This handles Twitter authetification and the connection to Twitter Streaming API\\n\",\n",
        "        \"            \\n\",\n",
        "        \"            #auth = OAuthHandler(consumer_key, consumer_secret)\\n\",\n",
        "        \"            #auth.set_access_token(access_token, access_token_secret)\\n\",\n",
        "        \"\\n\",\n",
        "        \"            auth=OAuthHandler(twitter_credentials.CONSUMER_KEY,twitter_credentials.CONSUMER_SECRET)\\n\",\n",
        "        \"            auth.set_access_token(twitter_credentials.ACCES_TOKEN,twitter_credentials.ACCES_TOKEN_SECRET)\\n\",\n",
        "        \"            \\n\",\n",
        "        \"\\n\",\n",
        "        \"        #            \\n\",\n",
        "        \"        self.auth = auth \\n\",\n",
        "        \"        self.api= tweepy.API(self.auth)            \\n\",\n",
        "        \"      \\n\",\n",
        "        \"\\n\",\n",
        "        \"    def clean_tweets(self,twitter_text):\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #use pre processor\\n\",\n",
        "        \"        tweet = ppr.clean(twitter_text)\\n\",\n",
        "        \"\\n\",\n",
        "        \"         #HappyEmoticons\\n\",\n",
        "        \"        emoticons_happy = set([\\n\",\n",
        "        \"            ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\\n\",\n",
        "        \"            ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\\n\",\n",
        "        \"            '=-3', '=3', ':-))', \\\":'-)\\\", \\\":')\\\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\\n\",\n",
        "        \"            'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\\n\",\n",
        "        \"            '<3'\\n\",\n",
        "        \"            ])\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Sad Emoticons\\n\",\n",
        "        \"        emoticons_sad = set([\\n\",\n",
        "        \"            ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\\n\",\n",
        "        \"            ':-[', ':-<', '=\\\\\\\\', '=/', '>:(', ':(', '>.<', \\\":'-(\\\", \\\":'(\\\", ':\\\\\\\\', ':-c',\\n\",\n",
        "        \"            ':c', ':{', '>:\\\\\\\\', ';('\\n\",\n",
        "        \"            ])\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #Emoji patterns\\n\",\n",
        "        \"        emoji_pattern = re.compile(\\\"[\\\"\\n\",\n",
        "        \"                 u\\\"\\\\U0001F600-\\\\U0001F64F\\\"  # emoticons\\n\",\n",
        "        \"                 u\\\"\\\\U0001F300-\\\\U0001F5FF\\\"  # symbols & pictographs\\n\",\n",
        "        \"                 u\\\"\\\\U0001F680-\\\\U0001F6FF\\\"  # transport & map symbols\\n\",\n",
        "        \"                 u\\\"\\\\U0001F1E0-\\\\U0001F1FF\\\"  # flags (iOS)\\n\",\n",
        "        \"                 u\\\"\\\\U00002702-\\\\U000027B0\\\"\\n\",\n",
        "        \"                 u\\\"\\\\U000024C2-\\\\U0001F251\\\"\\n\",\n",
        "        \"                 \\\"]+\\\", flags=re.UNICODE)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #combine sad and happy emoticons\\n\",\n",
        "        \"        emoticons = emoticons_happy.union(emoticons_sad)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        stop_words = set(stopwords.words('english'))\\n\",\n",
        "        \"        stop_words.update(['#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19','clean_text'])\\n\",\n",
        "        \"\\n\",\n",
        "        \"        word_tokens = word_tokenize(tweet)\\n\",\n",
        "        \"        #after tweepy preprocessing the colon symbol left remain after      \\n\",\n",
        "        \"        #removing mentions\\n\",\n",
        "        \"        tweet = re.sub(r':', '', tweet)\\n\",\n",
        "        \"        tweet = re.sub(r'‚Ä¶', '', tweet)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #replace consecutive non-ASCII characters with a space\\n\",\n",
        "        \"        tweet = re.sub(r'[^\\\\x00-\\\\x7F]+',' ', tweet)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #remove emojis from tweet\\n\",\n",
        "        \"        tweet = emoji_pattern.sub(r'', tweet)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #filter using NLTK library append it to a string\\n\",\n",
        "        \"        filtered_tweet = [w for w in word_tokens if not w in stop_words]\\n\",\n",
        "        \"\\n\",\n",
        "        \"        #looping through conditions\\n\",\n",
        "        \"        filtered_tweet = []    \\n\",\n",
        "        \"        for w in word_tokens:\\n\",\n",
        "        \"        #check tokens against stop words , emoticons and punctuations\\n\",\n",
        "        \"            if w not in stop_words and w not in emoticons and w not in string.punctuation:\\n\",\n",
        "        \"                filtered_tweet.append(w)\\n\",\n",
        "        \"\\n\",\n",
        "        \"        return ' '.join(filtered_tweet)            \\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"    def get_tweets(self,keyword, csvfile=None):\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        #df = pd.DataFrame(columns=self.cols)\\n\",\n",
        "        \"        \\n\",\n",
        "        \"        #if  csvfile is None:\\n\",\n",
        "        \"        #If the file exists, then read the existing data from the CSV file.\\n\",\n",
        "        \"        if os.path.exists(csvfile):\\n\",\n",
        "        \"            df = pd.read_csv(csvfile, header=None)\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            df=pd.DataFrame(columns=self.cols)\\n\",\n",
        "        \"            \\n\",\n",
        "        \"\\n\",\n",
        "        \"        #page attribute in tweepy.cursor and iteration\\n\",\n",
        "        \"        for page in tweepy.Cursor(self.api.search, q=keyword,count=200, include_rts=False).pages():\\n\",\n",
        "        \"\\n\",\n",
        "        \"            for status in page:\\n\",\n",
        "        \"                \\n\",\n",
        "        \"                new_entry = []\\n\",\n",
        "        \"                status = status._json\\n\",\n",
        "        \"                \\n\",\n",
        "        \"                #filter by language\\n\",\n",
        "        \"                if status['lang'] != 'en':\\n\",\n",
        "        \"                    continue\\n\",\n",
        "        \"\\n\",\n",
        "        \"                \\n\",\n",
        "        \"                #if this tweet is a retweet update retweet count\\n\",\n",
        "        \"                if status['created_at'] in df['created_at'].values:\\n\",\n",
        "        \"                    i = df.loc[df['created_at'] == status['created_at']].index[0]\\n\",\n",
        "        \"                    #\\n\",\n",
        "        \"                    cond1 = status['favorite_count'] != df.at[i, 'favorite_count']\\n\",\n",
        "        \"                    cond2 = status['retweet_count'] != df.at[i, 'retweet_count']\\n\",\n",
        "        \"                    if cond1 or cond2:\\n\",\n",
        "        \"                        df.at[i, 'favorite_count'] = status['favorite_count']\\n\",\n",
        "        \"                        df.at[i, 'retweet_count'] = status['retweet_count']\\n\",\n",
        "        \"                    continue\\n\",\n",
        "        \"                #print(status['text'])\\n\",\n",
        "        \"\\n\",\n",
        "        \"                #calculate sentiment\\n\",\n",
        "        \"                filtered_tweet =self.clean_tweets(status['text'])\\n\",\n",
        "        \"                blob = TextBlob(filtered_tweet)\\n\",\n",
        "        \"                Sentiment = blob.sentiment     \\n\",\n",
        "        \"                polarity = Sentiment.polarity\\n\",\n",
        "        \"                subjectivity = Sentiment.subjectivity\\n\",\n",
        "        \"\\n\",\n",
        "        \"                new_entry += [status['id'], status['created_at'],\\n\",\n",
        "        \"                              status['source'], status['text'],filtered_tweet, \\n\",\n",
        "        \"                              Sentiment,polarity,subjectivity, status['lang'],\\n\",\n",
        "        \"                              status['favorite_count'], status['retweet_count']]\\n\",\n",
        "        \"\\n\",\n",
        "        \"                new_entry.append(status['user']['screen_name'])\\n\",\n",
        "        \"\\n\",\n",
        "        \"                try:\\n\",\n",
        "        \"                    is_sensitive = status['possibly_sensitive']\\n\",\n",
        "        \"                except KeyError:\\n\",\n",
        "        \"                    is_sensitive = None\\n\",\n",
        "        \"\\n\",\n",
        "        \"                new_entry.append(is_sensitive)\\n\",\n",
        "        \"\\n\",\n",
        "        \"                hashtags = \\\", \\\".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\\n\",\n",
        "        \"                new_entry.append(hashtags) #append the hashtags\\n\",\n",
        "        \"\\n\",\n",
        "        \"                #\\n\",\n",
        "        \"                mentions = \\\", \\\".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\\n\",\n",
        "        \"                new_entry.append(mentions) #append the user mentions\\n\",\n",
        "        \"\\n\",\n",
        "        \"                try:\\n\",\n",
        "        \"                    xyz = status['place']['bounding_box']['coordinates']\\n\",\n",
        "        \"                    coordinates = [coord for loc in xyz for coord in loc]\\n\",\n",
        "        \"                except TypeError:\\n\",\n",
        "        \"                    coordinates = None\\n\",\n",
        "        \"                #\\n\",\n",
        "        \"                new_entry.append(coordinates)\\n\",\n",
        "        \"\\n\",\n",
        "        \"                try:\\n\",\n",
        "        \"                    location = status['user']['location']\\n\",\n",
        "        \"                except TypeError:\\n\",\n",
        "        \"                    location = ''\\n\",\n",
        "        \"                #\\n\",\n",
        "        \"                new_entry.append(location)\\n\",\n",
        "        \"                \\n\",\n",
        "        \"                #now append a row to the dataframe\\n\",\n",
        "        \"                single_tweet_df = pd.DataFrame([new_entry],columns=self.cols)\\n\",\n",
        "        \"                df_final = df.append(single_tweet_df, ignore_index=True)\\n\",\n",
        "        \"            \\n\",\n",
        "        \"            #save it to file\\n\",\n",
        "        \"            csvFile = open(csvfile, 'a' ,encoding='utf-8')\\n\",\n",
        "        \"            df_final.to_csv(csvFile,mode='a',columns=self.cols, encoding=\\\"utf-8\\\")\\n\",\n",
        "        \"          \\n\",\n",
        "        \"         \\n\",\n",
        "        \"        return df_final\\n\",\n",
        "        \"      \\n\",\n",
        "        \"   \\n\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"xBTVKcf575O0\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"covid_keywords = '#COVID19Ethiopia OR #COVID19Africa'  #hashtag based search\\n\",\n",
        "        \"#tweets_file = 'opia_covid19_23june2020.json'\\n\",\n",
        "        \"tweets_file='ethiopia_covid19_23june2020.csv'\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"\\n\",\n",
        "        \"#get data on keywords\\n\",\n",
        "        \"\\n\",\n",
        "        \"ts = tweetsearch()\\n\",\n",
        "        \"df = ts.get_tweets(covid_keywords, csvfile=tweets_file) \\n\",\n",
        "        \"   #you saved the \"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"l0EyRm9Y8H7M\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\",\n",
        "          \"height\": 164\n",
        "        },\n",
        "        \"outputId\": \"b0b2b74d-ab13-4bbd-9cb3-2fb9c5ce36f3\"\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"df.head(5)\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"execute_result\",\n",
        "          \"data\": {\n",
        "            \"text/html\": [\n",
        "              \"<div>\\n\",\n",
        "              \"<style scoped>\\n\",\n",
        "              \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
        "              \"        vertical-align: middle;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe tbody tr th {\\n\",\n",
        "              \"        vertical-align: top;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"\\n\",\n",
        "              \"    .dataframe thead th {\\n\",\n",
        "              \"        text-align: right;\\n\",\n",
        "              \"    }\\n\",\n",
        "              \"</style>\\n\",\n",
        "              \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
        "              \"  <thead>\\n\",\n",
        "              \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
        "              \"      <th></th>\\n\",\n",
        "              \"      <th>id</th>\\n\",\n",
        "              \"      <th>created_at</th>\\n\",\n",
        "              \"      <th>source</th>\\n\",\n",
        "              \"      <th>original_text</th>\\n\",\n",
        "              \"      <th>clean_text</th>\\n\",\n",
        "              \"      <th>sentiment</th>\\n\",\n",
        "              \"      <th>polarity</th>\\n\",\n",
        "              \"      <th>subjectivity</th>\\n\",\n",
        "              \"      <th>lang</th>\\n\",\n",
        "              \"      <th>favorite_count</th>\\n\",\n",
        "              \"      <th>retweet_count</th>\\n\",\n",
        "              \"      <th>original_author</th>\\n\",\n",
        "              \"      <th>possibly_sensitive</th>\\n\",\n",
        "              \"      <th>hashtags</th>\\n\",\n",
        "              \"      <th>user_mentions</th>\\n\",\n",
        "              \"      <th>place</th>\\n\",\n",
        "              \"      <th>place_coord_boundaries</th>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </thead>\\n\",\n",
        "              \"  <tbody>\\n\",\n",
        "              \"    <tr>\\n\",\n",
        "              \"      <th>0</th>\\n\",\n",
        "              \"      <td>1275067907710443524</td>\\n\",\n",
        "              \"      <td>Mon Jun 22 14:07:33 +0000 2020</td>\\n\",\n",
        "              \"      <td>&lt;a href=\\\"http://twitter.com/download/android\\\" ...</td>\\n\",\n",
        "              \"      <td>RT @Amref_Worldwide: Why wear a mask? Is it ne...</td>\\n\",\n",
        "              \"      <td>Why wear mask Is necessary Is required everyon...</td>\\n\",\n",
        "              \"      <td>(0.13333333333333333, 0.5666666666666667)</td>\\n\",\n",
        "              \"      <td>0.133333</td>\\n\",\n",
        "              \"      <td>0.566667</td>\\n\",\n",
        "              \"      <td>en</td>\\n\",\n",
        "              \"      <td>0</td>\\n\",\n",
        "              \"      <td>484</td>\\n\",\n",
        "              \"      <td>LGwara</td>\\n\",\n",
        "              \"      <td>None</td>\\n\",\n",
        "              \"      <td></td>\\n\",\n",
        "              \"      <td>Amref_Worldwide, daktari1</td>\\n\",\n",
        "              \"      <td>None</td>\\n\",\n",
        "              \"      <td>Nairobi</td>\\n\",\n",
        "              \"    </tr>\\n\",\n",
        "              \"  </tbody>\\n\",\n",
        "              \"</table>\\n\",\n",
        "              \"</div>\"\n",
        "            ],\n",
        "            \"text/plain\": [\n",
        "              \"                    id  ... place_coord_boundaries\\n\",\n",
        "              \"0  1275067907710443524  ...                Nairobi\\n\",\n",
        "              \"\\n\",\n",
        "              \"[1 rows x 17 columns]\"\n",
        "            ]\n",
        "          },\n",
        "          \"metadata\": {\n",
        "            \"tags\": []\n",
        "          },\n",
        "          \"execution_count\": 8\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"metadata\": {\n",
        "        \"id\": \"qgJLVXmR8pGW\",\n",
        "        \"colab_type\": \"code\",\n",
        "        \"colab\": {}\n",
        "      },\n",
        "      \"source\": [\n",
        "        \"\"\n",
        "      ],\n",
        "      \"execution_count\": null,\n",
        "      \"outputs\": []\n",
        "    }\n",
        "  ]\n",
        "} "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ed143793828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;34m\"!pip install tweet-preprocessor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       ],\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0;34m\"execution_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \"outputs\": [\n\u001b[1;32m     33\u001b[0m         {\n",
            "\u001b[0;31mNameError\u001b[0m: name 'null' is not defined"
          ]
        }
      ]
    }
  ]
}